{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a875fed",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"https://raw.githubusercontent.com/ProjectPythiaCookbooks/radar-cookbook/main/thumbnail.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd8a75",
   "metadata": {},
   "source": [
    "# ARM Data Quality Office ML Spike Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c70919-0a9f-4f52-83fb-bd3e6a541cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model Training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Performance Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "#Hyperparameter Tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8e292-7e00-4290-bfbd-72a99652ddab",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096562f5-8eb2-40c9-a91f-a1d0116d7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import act\n",
    "# Set your username and token here!\n",
    "# Read more on how to retrive your token:\n",
    "# https://arm-doe.github.io/ACT/API/generated/act.discovery.download_arm_data.html#act.discovery.download_arm_data\n",
    "username = \n",
    "token = \n",
    "\n",
    "datastream = \"nsametC1.b1\"\n",
    "target_variable='rh_mean'\n",
    "# Read NetCDF files\n",
    "from datetime import datetime\n",
    "startdate = '20200930'\n",
    "enddate = '20201210'\n",
    "files = act.discovery.download_arm_data(username, token, datastream, startdate, enddate)\n",
    "ds = act.io.read_arm_netcdf(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247c607",
   "metadata": {},
   "source": [
    "## Data Clearning - Missingness Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700a443",
   "metadata": {},
   "source": [
    "In this project, we aim to identify data quality spikes from time series data of the variable 'rh_mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e007c-a6cc-4d82-a194-ad1255367d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in list(ds):\n",
    "    if var != target_variable:\n",
    "        continue\n",
    "    if ds[var].isnull().any():\n",
    "        print(f'{var} contains NaN values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365249f1-5545-485d-8f56-66ce37d64588",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_single_chunk = ds.chunk(dict(time=-1))\n",
    "ds = ds_single_chunk.apply(lambda x: x.interpolate_na(dim='time', \n",
    "                                                      fill_value=\"extrapolate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a60715-82d6-4f44-a1b1-e0e3a9626f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in list(ds):\n",
    "    if var != target_variable:\n",
    "        continue\n",
    "    if ds[var].isnull().any():\n",
    "        print(f'{var} contains NaN values.')\n",
    "    else:\n",
    "        print('No variables in the dataset contain NaN values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee8435-a099-4958-b274-f52831437e07",
   "metadata": {},
   "source": [
    "# Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d18a2-9e2e-45c1-9ae0-79855ed9ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_filepath = 'labels_spike_detection_nsametC1.b1_rh_mean.txt'\n",
    "with open(label_filepath, 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "spike_intervals = np.array([line.split(' - ') for line in lines])\n",
    "\n",
    "vectorize_func = np.vectorize(np.datetime64)\n",
    "spike_intervals = vectorize_func(spike_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913fce01",
   "metadata": {},
   "source": [
    "Time intervals of DQ spikes were retrived from the DQ-Zoom Plotter.\n",
    "\n",
    "**Link:**\n",
    "https://dq.arm.gov/dq-zoom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23260d25-0807-4913-9a39-7f1f592b00e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spike_intervals # Time intervals retrived from DQ-Zoom Plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8c52f-f07c-4d1d-97f8-b5fca2a8bae9",
   "metadata": {},
   "source": [
    "# Generate Sliding Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31232929-ecb8-4a0b-b9c2-ebde1f1637af",
   "metadata": {},
   "source": [
    "## Windows without spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2950b-b45d-4280-8317-89d248105e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_mask = np.ones_like(ds.time.values, dtype=bool)\n",
    "# Exclude data that is marked as spikes.\n",
    "spike_time_ranges = [(np.datetime64(starttime, 'm'), np.datetime64(endtime, 'm')) \\\n",
    "                for starttime, endtime in spike_intervals]\n",
    "\n",
    "for start, end in spike_time_ranges:\n",
    "    normal_mask &= (ds.time.values < start) | (ds.time.values > end)\n",
    "ds_normal = ds.sel(time=normal_mask)\n",
    "ds_normal.time.shape, ds.time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce7427-6015-4845-9ed6-3a1cbd86f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_normal = ds_normal[target_variable].values\n",
    "time_steps=1\n",
    "diff_normal =  da_normal - np.roll(da_normal, shift = time_steps) # See Section 3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3da0b-7e7b-4dfe-ac99-2f19ad8bda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sliding windows for data without any spikes.\n",
    "windows_diff_normal = []\n",
    "window_size = 20\n",
    "stride = window_size//1\n",
    "for i in range(0, len(diff_normal) -  window_size + 1, stride):\n",
    "    window = diff_normal[i: i + window_size]\n",
    "    windows_diff_normal.append(window)\n",
    "\n",
    "windows_diff_normal = np.array(windows_diff_normal)\n",
    "windows_diff_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535821fa-854a-4000-8e10-570a57f778d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_diff_normal[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7a63b-5b49-40d8-9d5b-6e8e0a95473c",
   "metadata": {},
   "source": [
    "## Windows with spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968a2db-bbe0-4262-8dcd-d15bdbd13402",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_time = ds.time.values\n",
    "windows_time = []\n",
    "window_size = 20\n",
    "stride = window_size//10\n",
    "for i in range(0, len(da_time) -  window_size + 1, stride):\n",
    "    window = da_time[i: i + window_size]\n",
    "    windows_time.append(window)\n",
    "\n",
    "windows_time = np.array(windows_time)\n",
    "windows_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c2aee-9f52-4f18-95c5-3e6fbc96123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds[target_variable].values\n",
    "# time_steps=1\n",
    "diff =  da - np.roll(da, shift = time_steps)\n",
    "diff[:time_steps] = [0]*time_steps\n",
    "ds[f'diff_{target_variable}'] = (('time'), diff)\n",
    "\n",
    "# Generate sliding windows for data with spikes. Quite different from what's been done with windows without spikes. \n",
    "window_size = 20\n",
    "windows_diff_spike = []\n",
    "for idx, (start, end) in enumerate(spike_intervals):\n",
    "    start = np.datetime64(start, 'm')\n",
    "    end = np.datetime64(end, 'm')\n",
    "    spike_time_steps = (end - start).astype(int)\n",
    "    heading_time_steps = np.random.randint(0, window_size - spike_time_steps)\n",
    "    start_slicing = start-heading_time_steps\n",
    "    end_slicing = start_slicing +window_size - 1\n",
    "    window = ds.sel(time = slice(start_slicing, end_slicing))[f'diff_{target_variable}'].values\n",
    "    windows_diff_spike.append(window)\n",
    "\n",
    "windows_diff_spike = np.array(windows_diff_spike)\n",
    "windows_diff_spike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9664900-321b-4464-a2b9-c9a7254133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_diff_spike[0] # Can you spot a possible spike?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf9730-50ee-4fd4-bc31-9ec192fedfa3",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd7d2d-2727-411b-9129-7443370eb022",
   "metadata": {},
   "source": [
    "## (Repeat) First Order Differencing\n",
    "\n",
    "\"The first difference of a time series is the series of changes from one period to the next.\"\n",
    "\n",
    "**Reference**\n",
    "\n",
    "https://people.duke.edu/~rnau/411diff.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab31ee7-43fc-435a-9f9e-adb6aba0d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_steps = 1\n",
    "# diff =  da - np.roll(da, shift = time_steps)\n",
    "# diff[:time_steps] = [0]*time_steps\n",
    "# diff_normal =  da_normal - np.roll(da_normal, shift = time_steps)\n",
    "# diff_spike =  da_spike - np.roll(da_spike, shift = time_steps)\n",
    "# diff_normal[:time_steps] = [0]*time_steps\n",
    "# diff_spike[:time_steps] = [0]*time_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffe00c-2465-4715-b4e1-106dce255e6b",
   "metadata": {},
   "source": [
    "### Optional: Visualization of differences between every two time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0481121-15a9-455f-a48b-d2bf56aa75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(diff, bins=500, edgecolor='green')\n",
    "# plt.title('Distribution of 1st Order Differencing')\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bfde4-7171-4bcf-8da2-517e0d6dab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(da, bins=500, edgecolor='blue')\n",
    "# plt.title('Distribution of Original RH data')\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e54c1-97f0-43ab-b2f1-1f9c11710acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate quartiles\n",
    "# def make_box_plot(data, markOutliers=True, threshold=3):\n",
    "\n",
    "#     mu = np.mean(data)\n",
    "#     std = np.std(data)\n",
    "#     # Define outlier thresholds\n",
    "#     # threshold = 3. 0 means three standard deviations from the distribution mean\n",
    "#     # Three standard deviations from the mean is a statistical rule that states that \n",
    "#     # 99.7% of observed data falls within three standard deviations of the mean.\n",
    "#     upper_threshold = mu + threshold * std\n",
    "#     lower_threshold = mu - threshold * std\n",
    "#     outliers = data[(data < lower_threshold) | (data > upper_threshold)]\n",
    "    \n",
    "#     plt.boxplot(data)\n",
    "\n",
    "#     # Highlight outliers\n",
    "#     plt.plot(np.ones_like(outliers), outliers, 'ro', label='Outliers')\n",
    "    \n",
    "#     # Add legend and labels\n",
    "#     plt.title('Boxplot with Outliers Highlighted')\n",
    "#     plt.xlabel('Data')\n",
    "#     plt.ylabel('Values')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b29b91-9d9b-4f36-b9e9-003692417ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_box_plot(diff, threshold = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2b61b-dace-407c-b4b0-350cdf6de28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_box_plot(da, threshold = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712ff3b-6c93-415e-8a35-6cb8177889f7",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor\n",
    "\n",
    "The Variance Inflation Factor (VIF) is initially designed as a measure of multicollinearity within a set of multiple regression variables. I adopted this concept to develop features for our spike detection task. For further details on utilizing VIF to alleviate the effects of multicollinearity, please refer to this link.\n",
    "\n",
    "https://www.investopedia.com/terms/v/variance-inflation-factor.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e5af3-8d2a-4295-b53a-7b0b21e8a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_variance_normal = np.var(windows_diff_normal)\n",
    "\n",
    "window_vif_normal = []\n",
    "num_vif = 5\n",
    "min_var = 0.01\n",
    "idx_container = []\n",
    "for w in windows_diff_normal:\n",
    "    avg_deviation = np.abs(w - np.mean(w))\n",
    "    max_deviation_indices = avg_deviation.argsort()[-num_vif:][::-1] # Find out the most deviated data points within a time window.\n",
    "    window_var = np.var(w)\n",
    "    idx_container = []\n",
    "    vif = []\n",
    "    # Estimate how much the overall time window variance is inflated by the most deviated data points for each time window.\n",
    "    for idx in max_deviation_indices:\n",
    "        exclude_max_deviation_indices = [i not in idx_container for i in np.arange(len(w))]\n",
    "        exclude_max_deviation_var = np.var(w[exclude_max_deviation_indices])\n",
    "        idx_container.append(idx)\n",
    "        vif.append(window_var/max(exclude_max_deviation_var, min_var))\n",
    "    window_vif_normal.append(vif)\n",
    "window_vif_normal = np.array(window_vif_normal)\n",
    "window_vif_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa8765-6b1d-4b4a-bdeb-ade48231a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_vif_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81137a92-0324-444c-86fb-9428c1ec7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same process for windows with spikes. \n",
    "window_variance_spike = np.var(windows_diff_spike)\n",
    "\n",
    "window_vif_spike = []\n",
    "num_vif = 5\n",
    "min_var = 0.01\n",
    "idx_container = []\n",
    "for w in windows_diff_spike:\n",
    "    avg_deviation = np.abs(w - np.mean(w))\n",
    "    max_deviation_indices = avg_deviation.argsort()[-num_vif:][::-1]\n",
    "    window_var = np.var(w)\n",
    "    idx_container = []\n",
    "    vif = []\n",
    "    for idx in max_deviation_indices:\n",
    "        exclude_max_deviation_indices = [i not in idx_container for i in np.arange(len(w))]\n",
    "        exclude_max_deviation_var = np.var(w[exclude_max_deviation_indices])\n",
    "        idx_container.append(idx)\n",
    "        vif.append(window_var/max(exclude_max_deviation_var, min_var))\n",
    "    window_vif_spike.append(vif)\n",
    "window_vif_spike= np.array(window_vif_spike)\n",
    "window_vif_spike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49a47e-1f25-4fcb-9334-a63c9f4af230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_vif_spike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebae829-d89e-43fb-90a1-d4c586a9554b",
   "metadata": {},
   "source": [
    "## Maximum Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c1e29-d9e2-4ca3-8384-b60cd380caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deviation_normal = np.max(windows_diff_normal, axis=1).reshape(-1,1)\n",
    "max_deviation_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e1fd6-9878-4a96-9c69-e9b19c6f0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deviation_spike = np.max(windows_diff_spike, axis=1).reshape(-1,1)\n",
    "max_deviation_spike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The class ratio is {max_deviation_normal.shape[0]}:{max_deviation_spike.shape[0]}. Highly imbalanced! \\nIf we predict all samples to be without DQ spikes, we can easily achieve an impressive classification accuracy of {np.round(max_deviation_normal.shape[0]/ (max_deviation_normal.shape[0] + max_deviation_spike.shape[0])*100,1)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a1bfb-a308-40db-b5d7-cede99bdf83e",
   "metadata": {},
   "source": [
    "## Concatenate labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d80312-9d2b-4fdc-a0a5-7929bfaa4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_label = [0] * windows_diff_normal.shape[0]\n",
    "spike_label = [1]* windows_diff_spike.shape[0]\n",
    "label_combined = np.concatenate((normal_label, spike_label), axis=0)\n",
    "\n",
    "X_normal = np.hstack((window_vif_normal, max_deviation_normal))\n",
    "X_spike = np.hstack((window_vif_spike, max_deviation_spike))\n",
    "X = np.concatenate((X_normal, X_spike), axis=0)\n",
    "\n",
    "label_combined.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab128b-586f-448b-98a0-011e592f8b05",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee6fe3-63de-447f-8042-bdc4db7447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=1568\n",
    "np.random.seed(random_seed)\n",
    "perm = np.random.permutation(X.shape[0])\n",
    "X_shuffled =X[perm]\n",
    "label_shuffled = label_combined[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080b303-bf13-408f-9cd4-4e07113bc033",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c8352-a701-4ba0-bde2-f9d0c830f6a2",
   "metadata": {},
   "source": [
    "**Reference for train_test_split**\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab942dc-4290-4de4-a998-ae9edc39a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 1265\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, \n",
    "                                                    label_shuffled,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=label_shuffled\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ea90b-d4f5-4077-b478-7461c35cb884",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb474f6f-ffcc-4949-bcec-f9ecaa9923f3",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee94396-37dd-4a1a-8a05-d536f504bad3",
   "metadata": {},
   "source": [
    "**Logistic Regression**\\\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function. The implementation of logistic regression in scikit-learn can be accessed from class LogisticRegression. This implementation can fit binary, One-vs- Rest, or multinomial logistic regression with optional L2 or L1 regularization.\n",
    "\n",
    "**Reading Materials**\\\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b49bd-cead-4c55-9be1-8be5d8fc54b5",
   "metadata": {},
   "source": [
    "### Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc041b-2aa0-46b9-ba54-ec67b4940e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model using training data\n",
    "lr = LogisticRegression(random_state=5645, max_iter=200).fit(X_train, y_train)\n",
    "# Make predictions using the trained LR model\n",
    "y_train_pred_lr = lr.predict(X_train)\n",
    "# Calculate confusion matrix with training data\n",
    "conf_mx_lr = confusion_matrix(y_train, y_train_pred_lr, labels=[1,0])\n",
    "conf_mx_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040eb09-e74a-404d-8706-792ecaeead91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on testing data\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "# Calculate confusion matrix with testing data\n",
    "conf_mx_lr_test = confusion_matrix(y_test, y_test_pred_lr, labels=[1,0])\n",
    "conf_mx_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b33c4c-36ef-4222-abd9-00f1e9b0b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_lr = lr.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_lr = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85fb74-16c9-494e-92ad-c10c3b9de90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_curves(y_train, y_train_pred_prob, y_test, y_test_pred_prob, postfix='NA'):\n",
    "    \n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_prob, pos_label=1)\n",
    "    precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_pred_prob, pos_label=1)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_prob, pos_label=1)\n",
    "    precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_pred_prob, pos_label=1)\n",
    "    \n",
    "    roc_auc_train = auc(fpr_train, tpr_train)\n",
    "    roc_auc_test  = auc(fpr_test, tpr_test)\n",
    "\n",
    "    pr_auc_train  = auc(recall_train, precision_train)\n",
    "    pr_auc_test   = auc(recall_test, precision_test)\n",
    "    \n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr_train, tpr_train, color='darkorange', lw=2, label='ROC curve (area = %0.4f) - Train' % roc_auc_train)\n",
    "    plt.plot(fpr_train, tpr_train, color='orangered', lw=2, label='ROC curve (area = %0.4f) - Test' % roc_auc_test)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve - {postfix}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "                   \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall_train, precision_train, color='blue', lw=2, label='Precision-Recall curve (AUC = %0.2f) - Train' % pr_auc_train)\n",
    "    plt.plot(recall_test, precision_test, color='aqua', lw=2, label='Precision-Recall curve (AUC = %0.2f) - Test' % pr_auc_test)\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - {postfix}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eb4a1-9fcd-4c31-b31e-c9cefda04c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_curves(y_train, y_train_pred_prob_lr, y_test, y_test_pred_prob_lr, 'Logistic Regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a066102-d14d-4bc6-873d-d1cbb89e0f63",
   "metadata": {},
   "source": [
    "\"In situations where the dataset is highly imbalanced, the ROC curve can give an overly optimistic assessment of the model's performance. This optimism bias arises because the ROC curve's false positive rate (FPR) can become very small when the number of actual negatives is large.\"\n",
    "\n",
    "**Reference**\n",
    "\n",
    "https://juandelacalle.medium.com/how-and-why-i-switched-from-the-roc-curve-to-the-precision-recall-curve-to-analyze-my-imbalanced-6171da91c6b8#:~:text=In%20situations%20where%20the%20dataset,of%20actual%20negatives%20is%20large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20774530-5059-4284-9b78-508fed9d7f2f",
   "metadata": {},
   "source": [
    "### Penalized Logistic Regression\n",
    "\n",
    "**Ridge**\\\n",
    "Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of coefficients. The ridge coefficients minimize a penalized residual sum of squares. \n",
    "\n",
    "**Lasso**\\\n",
    "The Lasso is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. For this reason, Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero coefficients.\n",
    "\n",
    "**Elastic Net**\\\n",
    "ElasticNet is a linear regression model trained with L1 and L2 prior as regularizer. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of L1 and L2 using the l1_ratio parameter.\n",
    "Elastic-net is useful when there are multiple features which are correlated with one another. Lasso is likely to pick one\n",
    "of these at random, while elastic-net is likely to pick both.\n",
    "\n",
    "**References**\\\n",
    "[1] Ridge: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
    "\n",
    "[2] Lasso: https://scikit-learn.org/stable/modules/linear_model.html#lasso\n",
    "\n",
    "[3] Elastic Net: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#lasso-and-elastic-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91816d89-1dfc-4480-a44c-b5d33366cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_penalized = LogisticRegression(random_state=5645,\n",
    "                        max_iter=200,\n",
    "                        penalty='l2', \n",
    "                        C=0.1).fit(X_train, y_train)\n",
    "y_train_pred_lr_penalized = lr_penalized.predict(X_train)\n",
    "np.unique(y_train_pred_lr_penalized, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5981ae1-3a67-4428-8c4c-0f26fb3d8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_lr_penalized = confusion_matrix(y_train, y_train_pred_lr_penalized, labels=[1,0])\n",
    "conf_mx_lr_penalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e37b7-0d4f-4fa6-8840-f8f3bc42d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_lr_penalized = lr_penalized.predict(X_test)\n",
    "conf_mx_lr_penalized_test = confusion_matrix(y_test, y_test_pred_lr_penalized, labels=[1,0])\n",
    "conf_mx_lr_penalized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a167b-4243-41c6-893c-1e3a777c58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_lr_penalized = lr_penalized.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_lr_penalized = lr_penalized.predict_proba(X_test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_lr_penalized, y_test, y_test_pred_prob_lr_penalized, 'Penalized Logistic Regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a109e-b7da-4e21-8e4e-e70d2c8a0655",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation. \n",
    "\n",
    "**References**\n",
    "\n",
    "[1] https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "[2] https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe669b-3d6b-4e4b-acc0-78c710b64c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=5645, criterion='gini')\n",
    "dtree.fit(X_train, y_train)\n",
    "y_train_pred_dtree = dtree.predict(X_train)\n",
    "np.unique(y_train_pred_dtree, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953fa5b-229d-4536-a234-7a2ce366a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_dtree = confusion_matrix(y_train, y_train_pred_dtree, labels=[1,0])\n",
    "conf_mx_dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e3832-94d3-4eaf-a04e-7c2465ec0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on testing data\n",
    "y_test_pred_dtree = dtree.predict(X_test)\n",
    "# Calculate confusion matrix with testing data\n",
    "conf_mx_dtree_test = confusion_matrix(y_test, y_test_pred_dtree, labels=[1,0])\n",
    "conf_mx_dtree_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77287110-976b-49a6-a95d-121f61887bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_dtree = dtree.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_dtree = dtree.predict_proba(X_test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_dtree, y_test, y_test_pred_prob_dtree, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd682ff-9aff-43ef-b4ea-7ffea069eff3",
   "metadata": {},
   "source": [
    "## Regularized Decision Tree\n",
    "\n",
    "**How to restrict the growth of a Decision Tree**?\n",
    "\n",
    "**Reading Materials**\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a00d6-d1b5-4098-9ee6-307e5ebce838",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_regularized = DecisionTreeClassifier(random_state=5645, \n",
    "                                           criterion='gini', \n",
    "                                           max_depth=30, \n",
    "                                           min_samples_split=10,\n",
    "                                           # max_features='sqrt',\n",
    "                                           # min_samples_leaf = 10\n",
    "                                          )\n",
    "dtree_regularized.fit(X_train, y_train)\n",
    "y_train_pred_dtree_regularized = dtree_regularized.predict(X_train)\n",
    "np.unique(y_train_pred_dtree_regularized, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff10eb9-c476-43a7-aab2-b736f3869e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_dtree_regularized = confusion_matrix(y_train, y_train_pred_dtree_regularized, labels=[1,0])\n",
    "conf_mx_dtree_regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44039908-d567-44da-9141-97fd89cb41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on testing data\n",
    "y_test_pred_dtree_regularized = dtree_regularized.predict(X_test)\n",
    "# Calculate confusion matrix with testing data\n",
    "conf_mx_dtree_regularized_test = confusion_matrix(y_test, y_test_pred_dtree_regularized, labels=[1,0])\n",
    "conf_mx_dtree_regularized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c02ba8-c613-48b8-9ffe-7e50b939668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_dtree_regularized = dtree_regularized.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_dtree_regularized = dtree_regularized.predict_proba(X_test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_dtree_regularized, y_test, y_test_pred_prob_dtree_regularized, 'Regularized Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307a1ac-ff41-48d9-8e87-ac765ad00341",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "In random forests, each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.\n",
    "\n",
    "Furthermore, when splitting each node during the construction of a tree, the best split is found through an exhaustive search of the features values of either all input features or a random subset of size max_features. \n",
    "\n",
    "The purpose of these two sources of randomness is to decrease the variance of the forest estimator. Indeed, individual decision trees typically exhibit high variance and tend to overfit. The injected randomness in forests yield decision trees with somewhat decoupled prediction errors. By taking an average of those predictions, some errors can cancel out. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model.\n",
    "\n",
    "**References**\\\n",
    "[1] https://scikit-learn.org/stable/modules/ensemble.html#random-forests\n",
    "[2] https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332e056-e20c-4539-9b9d-211dc9cca1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd= RandomForestClassifier(n_jobs = -1, random_state=1110)\n",
    "rnd.fit(X_train, y_train)\n",
    "y_train_pred_rnd = rnd.predict(X_train)\n",
    "conf_mx_rnd = confusion_matrix(y_train, y_train_pred_rnd, labels=[1,0])\n",
    "conf_mx_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d12afc-bbbb-4330-9044-1a5d787c572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_rnd = rnd.predict(X_test)\n",
    "conf_mx_rnd_test = confusion_matrix(y_test, y_test_pred_rnd, labels=[1,0])\n",
    "conf_mx_rnd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d331b5-be11-466d-b5c1-f7d269fb41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_rnd = rnd.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_rnd = rnd.predict_proba(X_test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_rnd, y_test, y_test_pred_prob_rnd, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ed841-adc1-4570-825b-da99d35205a6",
   "metadata": {},
   "source": [
    "## Random Forest - Hyperparameter Tunning\n",
    "\n",
    "**Reading Materials**\\\n",
    "[1] \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "\n",
    "[2] https://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b1cf3-a2dc-4959-bc52-b9b8ffa03dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rnd = [{\n",
    "    'max_leaf_nodes':[50, 100],\n",
    "    'min_samples_leaf':[1, 20],\n",
    "    'n_estimators':[100, 500],\n",
    "    'max_features':[\"sqrt\", None],\n",
    "    'criterion': [\"entropy\"],\n",
    "    'random_state':[1110]\n",
    "}]\n",
    "\n",
    "rnd_grid = GridSearchCV(rnd, param_grid_rnd, cv=3)\n",
    "rnd_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30c698-4bfd-4538-9126-695341a8a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_grid.best_estimator_, rnd_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d63b22-086b-4ff7-a445-ce0fbc66b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rnd_grid = rnd_grid.predict(X_train)\n",
    "conf_mx_rnd_grid = confusion_matrix(y_train, y_train_pred_rnd_grid, labels=[1,0])\n",
    "conf_mx_rnd_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7085191-4db9-4336-bfc0-24478b47da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_rnd_grid = rnd_grid.predict(X_test)\n",
    "conf_mx_rnd_grid_test = confusion_matrix(y_test, y_test_pred_rnd_grid, labels=[1,0])\n",
    "conf_mx_rnd_grid_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c253714-1095-4a22-b586-d29a53f2698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_rnd_grid = rnd_grid.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_rnd_grid = rnd_grid.predict_proba(X_test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_rnd_grid, y_test, y_test_pred_prob_rnd_grid, 'Random Forest - 3 Fold CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f79af-8002-4f22-941d-b3610d57870d",
   "metadata": {},
   "source": [
    "## Use the best parameter values to build a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97a8d6-d0f7-4bd0-b16c-3addfbfe4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_select = RandomForestClassifier(n_jobs = -1, \n",
    "                                      random_state=1110,\n",
    "                                      # Update the following parameters with the best values you found with GridSearchCV.\n",
    "                                      # max_leaf_nodes=50,\n",
    "                                      # min_samples_leaf=1,\n",
    "                                      # max_features = 'sqrt',\n",
    "                                      # n_estimators=100,\n",
    "                                      # criterion='entropy',\n",
    "                                     )\n",
    "rnd_select.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e81dc-d3bb-4e42-a1c1-6fa2128ff14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rnd_select = rnd_select.predict(X_train)\n",
    "np.unique(y_train_pred_rnd_select, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70582c8e-97d4-41d6-b782-78f1953b4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_rnd_select = rnd_select.predict(X_test)\n",
    "np.unique(y_test_pred_rnd_select, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a062927-84fc-4afc-8c03-f46dc7533d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_rnd_select = confusion_matrix(y_train, y_train_pred_rnd_select, labels=[1,0])\n",
    "conf_mx_rnd_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332a288-445b-4ed9-b943-932f38bd3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_rnd_select_test = confusion_matrix(y_test, y_test_pred_rnd_select, labels=[1,0])\n",
    "conf_mx_rnd_select_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc98ce-be17-4dcd-8825-d6aa79a08000",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_rnd_select = rnd_select.predict_proba(X_train)[:,1]\n",
    "y_test_pred_prob_rnd_select = rnd_select.predict_proba(X_test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_rnd_select, y_test, y_test_pred_prob_rnd_select, 'Random Forest - Best Parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee05acb0-aaa8-49f1-a9f3-ef5f87a63440",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - PCA\n",
    "\n",
    "**Principal component analysis (PCA)**\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.\n",
    "\n",
    "**References**\\\n",
    "[1]https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA\n",
    "\n",
    "[2]https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html#sphx-glr-auto-examples-decomposition-plot-pca-iris-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c7588-ec17-4f5e-a68f-088373bdcac7",
   "metadata": {},
   "source": [
    "## PCA for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67400415-5036-4cda-911c-909e530ec540",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA()\n",
    "transformed_X = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae3c2e-ff71-4edf-b43f-3bbc1170f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_, sum(pca.explained_variance_ratio_[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98737ff6-77a3-49c1-a650-2ebacb7336b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=transformed_X[:, 0],\n",
    "    y=transformed_X[:, 1],\n",
    "    z=transformed_X[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=label_combined,  # Color by class label\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.5\n",
    "    ),\n",
    "    text=['Class: {}'.format(label) for label in label_combined],\n",
    ")])\n",
    "\n",
    "# Set layout\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='Principal Component 1',\n",
    "    yaxis_title='Principal Component 2',\n",
    "    zaxis_title='Principal Component 3',\n",
    "), title='3D Scatter Plot of First 3 Principal Components')\n",
    "\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973acde-a623-42d4-838c-25c343eac33c",
   "metadata": {},
   "source": [
    "## PCA Model Training - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b366673-c283-453f-b584-5477b7af3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pca_train = PCA(n_components=3)\n",
    "transformed_X_Train = pca_train.fit_transform(X_train_scaled)\n",
    "transformed_X_Test = pca_train.transform(X_test_scaled)\n",
    "rnd_pca = RandomForestClassifier(n_jobs = -1, \n",
    "                                      random_state=1110,\n",
    "                                      max_leaf_nodes=100,\n",
    "                                      min_samples_leaf=1,\n",
    "                                      max_features = 'sqrt',\n",
    "                                      n_estimators=500,\n",
    "                                      criterion='entropy'\n",
    "                                     )\n",
    "rnd_pca.fit(transformed_X_Train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74110040-9dc1-4c7d-ace8-b916c0a69fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rnd_pca = rnd_pca.predict(transformed_X_Train)\n",
    "np.unique(y_train_pred_rnd_pca, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c74cf3-5802-479a-a69e-02a86d70f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_rnd_pca = rnd_pca.predict(transformed_X_Test)\n",
    "np.unique(y_test_pred_rnd_pca, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6557c3b-04b9-4e28-8491-e5afa075451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_rnd_pca = confusion_matrix(y_train, y_train_pred_rnd_pca, labels=[1,0])\n",
    "conf_mx_rnd_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3f71e-033a-441a-ab36-82217cfccbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx_rnd_pca_test = confusion_matrix(y_test, y_test_pred_rnd_pca, labels=[1,0])\n",
    "conf_mx_rnd_pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c21a0-88aa-4163-aca0-0ddcb830b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob_rnd_pca = rnd_pca.predict_proba(transformed_X_Train)[:,1]\n",
    "y_test_pred_prob_rnd_pca = rnd_pca.predict_proba(transformed_X_Test)[:,1]\n",
    "plot_performance_curves(y_train, y_train_pred_prob_rnd_pca, y_test, y_test_pred_prob_rnd_pca, 'Random Forest - PCA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
